{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:43:19.990700Z",
     "start_time": "2024-06-03T09:43:19.987779Z"
    }
   },
   "source": [
    "import torch\n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "import ChatTTS\n",
    "from IPython.display import Audio"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:43:20.243228Z",
     "start_time": "2024-06-03T09:43:20.013041Z"
    }
   },
   "source": [
    "chat = ChatTTS.Chat()\n",
    "chat.load_models()\n",
    "\n",
    "# Use force_redownload=True if the weights updated.\n",
    "# chat.load_models(force_redownload=True)\n",
    "\n",
    "# If you download the weights manually, set source='locals'.\n",
    "# chat.load_models(source='local', local_path='YOUR LOCAL PATH')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:Load from cache: C:\\Users\\pduck/.cache/huggingface\\hub/models--2Noise--ChatTTS/snapshots\\ce5913842aebd78e4a01a02d47244b8d62ac4ee3\n",
      "WARNING:ChatTTS.utils.gpu_utils:No GPU found, use CPU instead\n",
      "INFO:ChatTTS.core:use cpu\n",
      "INFO:ChatTTS.core:vocos loaded.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\pduck\\\\.cache\\\\huggingface\\\\hub\\\\models--2Noise--ChatTTS\\\\snapshots\\\\ce5913842aebd78e4a01a02d47244b8d62ac4ee3\\\\config\\\\dvae.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m chat \u001B[38;5;241m=\u001B[39m ChatTTS\u001B[38;5;241m.\u001B[39mChat()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Use force_redownload=True if the weights updated.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# chat.load_models(force_redownload=True)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# If you download the weights manually, set source='locals'.\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# chat.load_models(source='local', local_path='YOUR LOCAL PATH')\u001B[39;00m\n",
      "File \u001B[1;32mD:\\code_store\\python3\\语音\\ChatTTS-main\\ChatTTS\\core.py:62\u001B[0m, in \u001B[0;36mChat.load_models\u001B[1;34m(self, source, force_redownload, local_path, **kwargs)\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mlog(logging\u001B[38;5;241m.\u001B[39mINFO, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoad from local: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlocal_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     60\u001B[0m     download_path \u001B[38;5;241m=\u001B[39m local_path\n\u001B[1;32m---> 62\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdownload_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mOmegaConf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdownload_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mconfig\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpath.yaml\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\code_store\\python3\\语音\\ChatTTS-main\\ChatTTS\\core.py:90\u001B[0m, in \u001B[0;36mChat._load\u001B[1;34m(self, vocos_config_path, vocos_ckpt_path, dvae_config_path, dvae_ckpt_path, gpt_config_path, gpt_ckpt_path, decoder_config_path, decoder_ckpt_path, tokenizer_path, device, compile)\u001B[0m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mlog(logging\u001B[38;5;241m.\u001B[39mINFO, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvocos loaded.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dvae_config_path:\n\u001B[1;32m---> 90\u001B[0m     cfg \u001B[38;5;241m=\u001B[39m \u001B[43mOmegaConf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdvae_config_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     91\u001B[0m     dvae \u001B[38;5;241m=\u001B[39m DVAE(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcfg)\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m dvae_ckpt_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdvae_ckpt_path should not be None\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32mD:\\code_env\\PYTHON\\python3\\Lib\\site-packages\\omegaconf\\omegaconf.py:189\u001B[0m, in \u001B[0;36mOmegaConf.load\u001B[1;34m(file_)\u001B[0m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_yaml_loader\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(file_, (\u001B[38;5;28mstr\u001B[39m, pathlib\u001B[38;5;241m.\u001B[39mPath)):\n\u001B[1;32m--> 189\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m    190\u001B[0m         obj \u001B[38;5;241m=\u001B[39m yaml\u001B[38;5;241m.\u001B[39mload(f, Loader\u001B[38;5;241m=\u001B[39mget_yaml_loader())\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(file_, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\pduck\\\\.cache\\\\huggingface\\\\hub\\\\models--2Noise--ChatTTS\\\\snapshots\\\\ce5913842aebd78e4a01a02d47244b8d62ac4ee3\\\\config\\\\dvae.yaml'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch infer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "texts = [\"So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\",]*3 \\\n",
    "        + [\"我觉得像我们这些写程序的人，他，我觉得多多少少可能会对开源有一种情怀在吧我觉得开源是一个很好的形式。现在其实最先进的技术掌握在一些公司的手里的话，就他们并不会轻易的开放给所有的人用。\"]*3     \n",
    "        \n",
    "wavs = chat.infer(texts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Audio(wavs[0], rate=24_000, autoplay=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Audio(wavs[3], rate=24_000, autoplay=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom params"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "params_infer_code = {'prompt':'[speed_5]', 'temperature':.3}\n",
    "params_refine_text = {'prompt':'[oral_2][laugh_0][break_6]'}\n",
    "\n",
    "wav = chat.infer('四川美食可多了，有麻辣火锅、宫保鸡丁、麻婆豆腐、担担面、回锅肉、夫妻肺片等，每样都让人垂涎三尺。', \\\n",
    "    params_refine_text=params_refine_text, params_infer_code=params_infer_code)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Audio(wav[0], rate=24_000, autoplay=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix random speaker"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rand_spk = chat.sample_random_speaker()\n",
    "params_infer_code = {'spk_emb' : rand_spk, }\n",
    "\n",
    "wav = chat.infer('四川美食确实以辣闻名，但也有不辣的选择。比如甜水面、赖汤圆、蛋烘糕、叶儿粑等，这些小吃口味温和，甜而不腻，也很受欢迎。', \\\n",
    "    params_refine_text=params_refine_text, params_infer_code=params_infer_code)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Audio(wav[0], rate=24_000, autoplay=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two stage control"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "text = \"So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\"\n",
    "chat.infer(text, refine_text_only=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "text = 'so we found being competitive and collaborative [uv_break] was a huge way of staying [uv_break] motivated towards our goals, [uv_break] so [uv_break] one person to call [uv_break] when you fall off, [uv_break] one person who [uv_break] gets you back [uv_break] on then [uv_break] one person [uv_break] to actually do the activity with.'\n",
    "wav = chat.infer(text, skip_refine_text=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from ChatTTS.experimental.llm import llm_api\n",
    "\n",
    "API_KEY = ''\n",
    "client = llm_api(api_key=API_KEY,\n",
    "        base_url=\"https://api.deepseek.com\",\n",
    "        model=\"deepseek-chat\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "user_question = '四川有哪些好吃的美食呢?'\n",
    "text = client.call(user_question, prompt_version = 'deepseek')\n",
    "print(text)\n",
    "text = client.call(text, prompt_version = 'deepseek_TN')\n",
    "print(text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "params_infer_code = {'spk_emb' : rand_spk, 'temperature':.3}\n",
    "\n",
    "wav = chat.infer(text, params_infer_code=params_infer_code)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
